---
author: HKL
categories:
- 默认分类
cid: 56
date: "2018-11-06T13:49:00Z"
slug: about-pps
status: publish
tags:
- Operating
- Linux
title: 包转发线速的衡量标准
updated: 2019/01/29 16:22:30
---


包转发线速的衡量标准是以单位时间内发送64byte的数据包（最小包）的个数作为计算基准的。对于千兆以太网来说，计算方法如 下：1,000,000,000bps/8bit/（64 + 8 + 12）byte=1,488,095pps 说明：当以太网帧为64byte时，需考虑8byte的帧头和12byte的帧间隙的固定开销。故一个线速的千兆以太网端口在转发64byte包时的包转 发率为1.488Mpps。快速以太网的线速端口包转发率正好为千兆以太网的十分之一，为148.8kpps。
*对于万兆以太网，一个线速端口的包转发率为14.88Mpps。
*对于千兆以太网，一个线速端口的包转发率为1.488Mpps。
*对于快速以太网，一个线速端口的包转发率为0.1488Mpps。


<!--more-->


最初PCI总线是32bit，33Mhz，这样带宽为133Mbps。

接着因为在服务器领域传输要求Intel把总线位数提高到64，这样又出现了2种PCI总线，分别为64bit/33Mhz和64bit/66Mhz，当 然带宽分别翻倍了，为266Mbps和533Mbps，这个比较通常的名称应该是pci-64，但这好像是intel自己做的，没有行业标准。

稍后一段时间，在民用领域，单独开发出了AGP，32bit，66Mhz，这样带宽为266Mbps，再加上后来AGP2.0的2X和4X标准，最高4X的带宽高达1Gbps，但是这个只是为显卡设计的。

同时服务器领域也没闲着，几家厂商联合制定了PCI-X，这个就是真正PCI下一代的工业标准了，其实也没什么新意，就是64bit，133Mhz版本的 PCI，那这样带宽就为1Gbps，后来PCI-X 2.0,3.0又分别提升频率，经历过266Mhz，533Mhz，甚至1GMhz，各位自己算带宽吧，我乘法学的不好，这个带宽可以说是非常足够的了， 不过这个时候PCI也面临一些问题：一方面是频率提高造成的并行信号串扰，另一方面是共享式总线造成的资源争用，总之也就是说虽然规格上去了，但实际效果 可能跑不了这些指标。

然后就是我们目前的明星pci-E了，这个标准应该是和pci-X同时出现的，但是由于当时用不到这么高带宽，并且不像pci-X一样兼容老pci板卡， 所以一直没什么发展，直到最近民用领域显卡带宽又不够了，服务器领域对pci-X也觉得不爽了，pci-E才真正显出优势来，目前这个标准应该会替代 agp和pci-X，成为民用和服务器两大领域的统一标准。

PCI-E标准的最大特点就是串行总线，和普通pci的区别类似于ide和sata的区别，具体说起来就比较麻烦了，简单来看指标的话，频率为 2.5Ghz（这个恐怖，串行的好处，同样因为串行，位宽就没意义了，但是据说是什么8bit/10bit的传输），带宽 pci-E 1X单向传输250MBps，双向也就500了，同时pci-e的倍速最高可达16X，多少就自己乘吧，要注意的是pci-e不存在共享问题，也就是说挂 在总线上的任何一个设备都会达到这个速度而不是所有设备带宽的总合。下面引用一篇文章的一段，感兴趣的自己看一下：

在工作原理上，PCI Express与并行体系的PCI没有任何相似之处，它采用串行方式传输数据，而依靠高频率来获得高性能，因此PCI Express也一度被人称为“串行PCI”。由于串行传输不存在信号干扰，总线频率提升不受阻碍，PCI Express很顺利就达到2.5GHz的超高工作频率。其次，PCI Express采用全双工运作模式，最基本的PCI Express拥有4根传输线路，其中2线用于数据发送，2线用于数据接收，也就是发送数据和接收数据可以同时进行。相比之下，PCI总线和PCI-X总 线在一个时钟周期内只能作单向数据传输，效率只有PCI Express的一半；加之PCI Express使用8b/10b编码的内嵌时钟技术，时钟信息被直接写入数据流中，这比PCI总线能更有效节省传输通道，提高传输效率。第三，PCI Express没有沿用传统的共享式结构，它采用点对点工作模式（Peer to Peer，也被简称为P2P），每个PCI Express设备都有自己的专用连接，这样就无需向整条总线申请带宽，避免多个设备争抢带宽的糟糕情形发生，而此种情况在共享架构的PCI系统中司空见 惯。

由于工作频率高达2.5GHz，最基本的PCI Express总线可提供的单向带宽便达到250MBps（2.5Gbps×1 B/8bit×8b/10b=250MBps），再考虑全双工运作，该总线的总带宽达到500MBps—这仅仅是最基本的PCI Express ×1模式。如果使用两个通道捆绑的×2模式，PCI Express便可提供1GBps的有效数据带宽。依此类推，PCI Express ×4、×8和×16模式的有效数据传输速率分别达到2GBps、4GBps和8GBps。这与PCI总线可怜的共享式133MBps速率形成极其鲜明的对 比，更何况这些都还是每个PCI Express可独自占用的带宽。

总之写这么多废话，目的就是说明就系统总线来说，承受高带宽，高pps是没问题的。

再上面有人说即使总线没限制，cpu也会成为瓶颈，这话有一定道理，其实关键在于高pps带来的恐怖中断flood，其实对于这么高的中断，i386的 apic（高级中断控制）是完全处理的来，瓶颈是在操作系统的中断处理程序上了，这方面问题就由操作系统来解决了，所以不是什么不可能完成的任务，实际上 目前也都有很成熟的方案了，比如BSD系统的网卡Polling，Linux也有，具体叫什么我忘记了。

还是那句话，别对i386没信心，也别对目前的PC架构计算机的能力有任何怀疑，事实证明，这样的搭配至少能满足90%的应用需要。

**一. 线速**

线速转发是对一个网络中转设备的理想要求。但平时大多数人都关注着设备的bps（bits per second，每秒数据的位数），很少人会想到fps（frame per second，每秒数据的帧数）实际上更考验设备的转发能力。

简单的说，bps是指每秒钟有多少字节的数据经过，fps是每秒钟有多少个数据包经过。

以10Mb的网络来说，线速时bps为10M，fps最大值为14880。

那么这个14880是怎么计算出来的呢？

首先我们要知道几个规定：

1. 以太网内最小的数据包的大小为64字节，它包括4字节的CRC，2字节的以太网类型（或长度），6字节的源Mac地址，6字节的目的Mac地址以及46字节的负荷。

2. 以太网帧与帧之间至少要有96位（12字节）的帧间隙（IFP，inter frame gap）以确保区分两个数据包。

3. 每个数据帧开始之间必须要有8字节的Mac地址前导位（MAC preamble）以确保发送方接收方同步数据位。

因此，以太网内最小的数据包实际上是64+12+8=84字节=672位。

于是，10M网络环境下fps的最大值就是

10M位每秒 / 672 位每帧 = 14480 帧每秒。

同理，我们可以算出10M网络环境下fps的最大值为

10M位每秒 / ( ( 1518+12+8 ) * 8 ) 位每帧 = 812 帧每秒

而100M网络环境下这两个值分别为148809和8127。

**二. 处理能力**

我们已经知道了线速情况下最大的fps值，现在我们看看要达到线速所需要的处理能力。

假设市面上某防火墙的是X86架构的CII 900Mhz 的CPU，即每秒钟可以分成900M个时钟周期。

于是，在100M的网络环境下，处理一个数据帧所允许的最大时钟周期为：

900M 时钟周期每秒 / 148809 帧每秒 = 6048 时钟周期每帧

也就是说，要达到线速转发，900Mhz的CPU平均要在6048个时钟周期内完成对一个数据包的处理。

这只是理想情况，基于x86架构的系统里CPU还要负责各类中断（如系统时钟）的处理，每次中断时都要保存当前的运行状态，切换到中断处理程序，等中断处 理完后，再恢复当前状态，切换回原来的处理流程。光是这个切换过程至少都要费上500个时钟周期，还不包括中断处理程序所用的时钟周期。好在这类中断还” 不算“频繁，扣除系统这部分开销后，真正分摊到每个数据包的处理时间平均大约还有5500个时钟周期。

虽然Intel P3以上级的CPU如CII在设计指令集时已经将大量常用的指令（如两个寄存器相加/减）优化到可以在一个时钟周期内完成，但做为防火墙，更常用的是读 /写内存数据（比如要比较源地址，计算IP的校验和等）这类多时钟周期的指令，所以5500个时钟周期内大约只能执行2000条指令。

对一个数据包的处理，从为这个数据包分配内存起，依次要检查以太网络协议（如果是RFC1042格式的数据包还要跳过LLC头找真正的以太网络协议），检 查IP头、校验和（如果是TCP/UDP协议还要计算对应的校验和），DoS防御，状态检测，NAT规则，安全/统计规则，更新ARP/路由表，选择转发 网卡，直到最终把这个数据包添加到发送队列中才算完成。


总线是一组进行互连和传输信息（指令、数据和地址）的信号线。主要参数有总线位宽、总线时钟频率和总线传输速率。

※总线位宽决定输入/输出设备之间一次数据传输的信息量，用位（bit）表示，如总线宽度为8位、16位、32位和64位。

※总线时钟频率是总线的工作频率，以 MHz 表示。

※总线传输速率是总线上每秒钟所能传输的最大字节数。通过总线宽度和总线时钟频率来计算总线传输速率。

**一. 并行总线。**

并行总线带宽(MB/s) = 并行总线时钟频率(MHz) * 并行总线位宽(bit/8 = B) * 每时钟传输几组数据(cycle)

●PCI 总线位宽是 32位，总线频率 33 MHz，每时钟传输 1 组数据，它的带宽为 127.2 MB/s，即 1017.6 Mbps。

●PCI 2.1 总线位宽是 64位，总线频率 66 MHz，每时钟传输 1 组数据，它的带宽为 508.6 MB/s，即 4068.8 Mbps。

●AGP 总线位宽是 32位，总线频率 66 MHz，每时钟传输 1 组数据，它的带宽为 254.3 MB/s，即 2034.4 Mbps。

●AGP Pro 总线位宽是 32位，总线频率 66 MHz，每时钟传输 1 组数据，它的带宽为 254.3 MB/s，即 2034.4 Mbps。

AGP Pro 是 AGP 的改进型，它使工作站级主板也能利用 AGP 的加速性能，降低了 AGP 所需的电压供应，并没有什么太大的改变。

●AGP 2X 总线位宽是 32位，总线频率 66 MHz，每时钟传输 2 组数据，它的带宽为 508.6 MB/s，即 4068.8 Mbps。

●AGP 4X 总线位宽是 32位，总线频率 66 MHz，每时钟传输 4 组数据，它的带宽为 1017.3 MB/s，即 8138.4 Mbps。

●AGP 8X 总线位宽是 32位，总线频率 66 MHz，每时钟传输 8 组数据，它的带宽为 2034.6 MB/s，即 16276.8 Mbps。

顺带说说：

○ISA 总线位宽是 16位，总线频率 8.3 MHz，每时钟传输 1 组数据，它的带宽为 15.9 MB/s，即 127.2 Mbps。

○EISA 总线位宽是 32位，总线频率 8.3 MHz，每时钟传输 1 组数据，它的带宽为 31.8 MB/s，即 254.4 Mbps。


**二. 串行总线。**

好，该说最新的 PCI Express 了，和上面这些并行总线不同的是，PCI Express 属于串行总线，总线带宽和总线时钟频率的概念与并行总线完全相同，只是它改变了传统意义上的总线位宽的概念。串行总线采用多条管线（或通道）的做法实现更 高的速度，管线之间各自独立，多条管线组成一条总线系统。如 PCI Express x1，PCI Express x2，PCI Express x16 等。

PCI Express 总线频率 2500 MHz，这是在 100 MHz 的基准频率通过锁相环振荡器(Phase Lock Loop，PLL)达到的。

串行总线带宽(MB/s) = 串行总线时钟频率(MHz) * 串行总线位宽(bit/8 = B) * 串行总线管线 * 编码方式 * 每时钟传输几组数据(cycle)


◆PCI Express x1 总线位宽是 1位，总线频率 2500 MHz，串行总线管线是 1 条，每时钟传输 2 组数据，编码方式为 8b/10b，它的带宽为 476.84 MB/s，即 3814.7 Mbps。（带宽是 PCI 的 3.75 倍。）

公式是 2500000000(Hz) * 1/8(bit) * 1(条管线) * 8/10(bit) * 2(每时钟传输2组数据) = 500000000 B/s = 476.8371582 MB/s，即 3814.6972656 Mbps。

下面给出其它类型组合的带宽。
◆PCI Express x2 的带宽为 953.68 MB/s，即 7629.4 Mbps。（此模式仅用于主板内部接口而非插槽模式）

◆PCI Express x4 的带宽为 1907.36 MB/s，即 15258.9 Mbps。

◆PCI Express x8 的带宽为 3814.72 MB/s，即 30517.8 Mbps。

◆PCI Express x16 的带宽为 7629.44 MB/s，即 61035.5 Mbps。（带宽是 AGP 8X 的 3.75 倍。）

◆PCI Express x32 的带宽为 15258.88 MB/s，即 122071 Mbps。


可能有朋友感觉在这看到的带宽数据比别处看到的值要小，因为我采录的是实际数据，而非文稿数据。就如同说硬盘 160 GB，而实际能用的只有 153 GB 左右。

感兴趣的朋友请接着往下看！

PCI 的带宽常被引述为 132 MB/秒，这是文稿数据，它的实际带宽是 127.2 MB/秒。

造成如此差异是因为：

1. 对工作频率具体数值引用的不同。

2. 容量单位上存在二进制计量与十进制计量，132 MB/秒来源于十进制计量，127.2 MB/秒来源于二进制计量。

并行总线带宽(MB/s) = 并行总线时钟频率(MHz) * 并行总线位宽(bit/8 = B) * 每时钟传输几组数据(cycle)

B/s = Hz * bytes * cycle

MB/s = MHz * bytes * cycle

132 MB/秒：

PCI 的工作频率是 33 MHz, 即 33 MHz * 1000000 = 33000000 Hz。

PCI 的位宽是 32 bits, 即 4 bytes。

PCI 每时钟传输 1 组数据。

33000000 Hz * 4 bytes * 1 cycle = 132000000 byte/s 除以 10的6次方(容量以十进制计量) = 132 megabyte/s = 132 MB/s

而 127.2 MB/秒：

PCI 的工作频率是以 30ns 来表示，X ns 的倒数 * 1000 = Y MHz，即 30 ns 的倒数 * 1000 = 33.333333 MHz，33.333333 MHz * 1000000 = 33333333 Hz。

PCI 的位宽是 32 bits, 即 4 bytes。

PCI 每时钟传输 1 组数据。

33333333 Hz * 4 bytes * 1 cycle = 133333332 byte/s 除以 2的20次方(容量以二进制计量) = 127.1566 mebibyte/s = 127.2 MB/s = 1017.6 Mb/


PCI是由Intel公司1991年推出的一种局部总线。从结构上看，PCI是在CPU和原来的系统总线 之间插入的一级总线，具体由一个桥接电路实现对这一层的管理，并实现上下之间的接口以协调数据的传送。管理器提供了信号缓冲，使之能支持10种外设，并能 在高时钟频率下保持高性能，它为显卡，声卡，网卡，MODEM等设备提供了连接接口，它的工作频率为33MHz/66MHz。

最早提出的PCI 总线工作在33MHz 频率之下，传输带宽达到了133MB/s(33MHz X 32bit/8)，基本上满足了当时处理器的发展需要。随着对更高性能的要求，1993年又提出了64bit 的PCI 总线，后来又提出把PCI 总线的频率提升到66MHz 。

PCI的标准从V1.0到目前的V2.2 V2.3,但好像有被PCI-E取代的趋势.



本文转自：http://www.ourlinux.net/network/pps-jisuan/

